--Hadoop
HDFS: Hadoop分布文件系统（核心）
MapReduce: 分布式计算框架（核心）
Yarn: 集群资源管理系统（核心）
Sqoop: 数据同步工具
Pig: 基于Hadoop的数据流系统
Mahout: 数据挖掘算法库
Flume: 日志收集工具

-----------------------------------------------------------------------------------

-HDFS
  Client  --切分文件，访问HDFS，与NameNode交互获取文件位置信息，与DataNode交互读取和写入数据
  Namenode  --Master节点,管理HDFS名称空间和数据块映射信息（fsimage、fsedits）
  Secondarynode  --定期合并fsimage、fsedits，可紧急辅助恢复NameNode
  Datanode --数据存储节点，汇报存储信息给NameNode
  Block -- 128MB，可多副本
  
-MapReduce
  JobTracker  --Mster节点只有一个，管理所有任务的监控、错误处理。分解任务分派给TaskTracker
  TaskTracker  --Slave节点，多台。与JobTracker交互汇报任务状态。运行MAP TASK、Reduce Task
  Map Task  --解析数据记录，将输出结果写入本地磁盘
  Reducer Task  --远程读取Map Task执行结果中的输入数据，进行排序
   
-Yarn 
  Resourcemanager  --处理客户端请求，启劢、监控 ApplicationMaster，监控 NodeManager，资源分配不调度
  Nodemanager  --单个节点上的资源管理，处理来自 ResourceManager、ApplicationMaster 的命令
  ApplicationMaster  --数据切分，为应用程序申请资源,幵分配给内部仸务，仸务监控不容错
  Container  --对任务运行行环境的抽象,封装了CPU、内存。运行相关的信息资源分配与调度
  Client  --用户与YARN交互的客户端程序，提交应用程序、监控应用程序状态,杀死应用程序等
  
########################################################################################

[root@nn01 ~]# tar -xf hadoop-2.7.6.tar.gz
[root@nn01 ~]#  mv hadoop-2.7.6 /usr/local/hadoop
[root@nn01 ~]# cd /usr/local/hadoop/
[root@nn01 hadoop]# rpm -ql  java-1.8.0-openjdk
[root@nn01 hadoop]# cd ./etc/hadoop/
[root@nn01 hadoop]# vim hadoop-env.sh
25 export JAVA_HOME="/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.131-11.b12.el7.x86_64/jre"
33 export HADOOP_CONF_DIR="/usr/local/hadoop/etc/hadoop"
[root@nn01 ~]# cd /usr/local/hadoop/
[root@nn01 hadoop]# mkdir /usr/local/hadoop/aa
[root@nn01 hadoop]# cp *.txt /usr/local/hadoop/aa
[root@nn01 hadoop]# ./bin/hadoop jar  \
 share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar  wordcount aa bb 
   //wordcount为参数 统计aa这个文件夹，存到bb这个文件里面（这个文件不能存在，要是存在会报错，是为了防止数据覆盖）
   
###################################################################################

--Hadoop分布式
vim /usr/local/hadoop/etc/hadoop/core-site.xml  //核心配置文件
<configuration>
        <property>
                <name>fs.defaultFS</name>
                <value>hdfs://hadoop-nn01:9000</value>
        </property>
        <property>
                <name>hadoop.tmp.dir</name>
                <value>/var/hadoop</value>
        </property>
</configuration>

mkdir /var/hadoop
for i in node{1..3}; do ssh $i mkdir /var/hadoop;done

vim /usr/local/hadoop/etc/hadoop/hdfs-site.xml  //HDFS配置文件
<configuration>
        <property>
                <name>dfs.namenode.http-address</name>
                <value>hadoop-nn01:50070</value>
        </property>
        <property>
                <name>dfs.namenode.secondary.http-address</name>
                <value>hadoop-nn01:50090</value>
        </property>
        <property>
                <name>dfs.replication</name>
                <value>2</value>
        </property>
</configuration>

rpm -ql  java-1.8.0-openjdk
vim /usr/local/hadoop/etc/hadoop/hadoop-env.sh
25 export JAVA_HOME="/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.131-11.b12.el7.x86_64/jre"
33 export HADOOP_CONF_DIR="/usr/local/hadoop/etc/hadoop"

vim /usr/local/hadoop/etc/hadoop/slaves
node1
node2
node3

for i in node{1..3}; do scp -r /usr/local/hadoop $i:/usr/local/hadoop; done

[root@nn01 hadoop]# cd /usr/local/hadoop/
[root@nn01 hadoop]# ./bin/hdfs namenode -format     //格式化 namenode
[root@nn01 hadoop]# ./sbin/start-dfs.sh    //启动
[root@nn01 hadoop]# jps    //验证角色
23408 NameNode
23700 Jps
23591 SecondaryNameNode
[root@nn01 hadoop]# ./bin/hdfs dfsadmin -report    //查看集群是否组建成功
Live datanodes (3):    //有三个角色成功

